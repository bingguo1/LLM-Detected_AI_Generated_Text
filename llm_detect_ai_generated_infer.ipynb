{"cells":[{"cell_type":"markdown","metadata":{},"source":["# LLM - Detect AI Generated Text\n"]},{"cell_type":"markdown","metadata":{},"source":["# 🛠 | Install Libraries "]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-03T01:32:15.845264Z","iopub.status.busy":"2023-11-03T01:32:15.844896Z","iopub.status.idle":"2023-11-03T01:33:03.106115Z","shell.execute_reply":"2023-11-03T01:33:03.104805Z","shell.execute_reply.started":"2023-11-03T01:32:15.845213Z"},"trusted":true},"outputs":[],"source":["!pip install /kaggle/input/llm-science-exam-lib-ds/keras_core-0.1.7-py3-none-any.whl --no-deps\n","!pip install /kaggle/input/llm-science-exam-lib-ds/keras_nlp-0.6.2-py3-none-any.whl --no-deps"]},{"cell_type":"markdown","metadata":{},"source":["# 📚 | Import Libraries "]},{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-11-03T01:33:03.108798Z","iopub.status.busy":"2023-11-03T01:33:03.108468Z","iopub.status.idle":"2023-11-03T01:33:16.609984Z","shell.execute_reply":"2023-11-03T01:33:16.609177Z","shell.execute_reply.started":"2023-11-03T01:33:03.108769Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-22 16:26:37.030899: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-12-22 16:26:37.050468: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-22 16:26:37.050485: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-22 16:26:37.050970: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-22 16:26:37.054631: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-22 16:26:37.385459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"name":"stdout","output_type":"stream","text":["Using PyTorch backend.\n"]}],"source":["import os\n","os.environ[\"KERAS_BACKEND\"] = \"torch\"  # or \"tensorflow\" or \"torch\"\n","\n","import keras_nlp\n","import keras_core as keras \n","import keras_core.backend as K\n","\n","\n","import jax\n","import tensorflow as tf\n","# from tensorflow import keras\n","# import tensorflow.keras.backend as K\n","\n","import numpy as np \n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","\n","from glob import glob\n","from tqdm.notebook import tqdm\n","import gc"]},{"cell_type":"markdown","metadata":{},"source":["## Library Version"]},{"cell_type":"code","execution_count":2,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-11-03T01:33:16.611652Z","iopub.status.busy":"2023-11-03T01:33:16.61113Z","iopub.status.idle":"2023-11-03T01:33:16.616769Z","shell.execute_reply":"2023-11-03T01:33:16.615935Z","shell.execute_reply.started":"2023-11-03T01:33:16.611625Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow: 2.15.0\n","Keras: 0.1.7\n","KerasNLP: 0.6.3\n"]}],"source":["print(\"TensorFlow:\", tf.__version__)\n","# print(\"JAX:\", jax.__version__)\n","print(\"Keras:\", keras.__version__)\n","print(\"KerasNLP:\", keras_nlp.__version__)"]},{"cell_type":"markdown","metadata":{},"source":["# ⚙️ | Configuration"]},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-11-03T01:33:16.619977Z","iopub.status.busy":"2023-11-03T01:33:16.619702Z","iopub.status.idle":"2023-11-03T01:33:16.636453Z","shell.execute_reply":"2023-11-03T01:33:16.635641Z","shell.execute_reply.started":"2023-11-03T01:33:16.619948Z"},"trusted":true},"outputs":[],"source":["class CFG:\n","    verbose = 0  # Verbosity\n","    device = 'GPU'  # Device\n","    seed = 42  # Random seed\n","    batch_size = 6  # Batch size\n","    drop_remainder = True  # Drop incomplete batches\n","    ckpt_dir = \"./\"  # \"/kaggle/input/daigt-kerasnlp-ckpt\"  # Name of pretrained models\n","    sequence_length = 200  # Input sequence length\n","    class_names = ['real','fake']  # Class names [A, B, C, D, E]\n","    num_classes = len(class_names)  # Number of classes\n","    class_labels = list(range(num_classes))  # Class labels [0, 1, 2, 3, 4]\n","    label2name = dict(zip(class_labels, class_names))  # Label to class name mapping\n","    name2label = {v: k for k, v in label2name.items()}  # Class name to label mapping"]},{"cell_type":"markdown","metadata":{},"source":["# ♻️ | Reproducibility \n","Sets value for random seed to produce similar result in each run."]},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-11-03T01:33:16.637699Z","iopub.status.busy":"2023-11-03T01:33:16.637422Z","iopub.status.idle":"2023-11-03T01:33:16.653097Z","shell.execute_reply":"2023-11-03T01:33:16.65216Z","shell.execute_reply.started":"2023-11-03T01:33:16.637675Z"},"trusted":true},"outputs":[],"source":["keras.utils.set_random_seed(CFG.seed)"]},{"cell_type":"markdown","metadata":{},"source":["# 💾 | Hardware\n","Following codes automatically detects hardware (TPU or GPU). "]},{"cell_type":"code","execution_count":5,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-11-03T01:33:16.654458Z","iopub.status.busy":"2023-11-03T01:33:16.654211Z","iopub.status.idle":"2023-11-03T01:33:16.662026Z","shell.execute_reply":"2023-11-03T01:33:16.661293Z","shell.execute_reply.started":"2023-11-03T01:33:16.654437Z"},"trusted":true},"outputs":[],"source":["def get_device():\n","    \"Detect and intializes GPU/TPU automatically\"\n","    try:\n","        # Connect to TPU\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() \n","        # Set TPU strategy\n","        strategy = tf.distribute.TPUStrategy(tpu)\n","        print(f'> Running on TPU', tpu.master(), end=' | ')\n","        print('Num of TPUs: ', strategy.num_replicas_in_sync)\n","        device=CFG.device\n","    except:\n","        # If TPU is not available, detect GPUs\n","        gpus = tf.config.list_logical_devices('GPU')\n","        ngpu = len(gpus)\n","         # Check number of GPUs\n","        if ngpu:\n","            # Set GPU strategy\n","            strategy = tf.distribute.MirroredStrategy(gpus) # single-GPU or multi-GPU\n","            # Print GPU details\n","            print(\"> Running on GPU\", end=' | ')\n","            print(\"Num of GPUs: \", ngpu)\n","            device='GPU'\n","        else:\n","            # If no GPUs are available, use CPU\n","            print(\"> Running on CPU\")\n","            strategy = tf.distribute.get_strategy()\n","            device='CPU'\n","    return strategy, device"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T01:33:16.663112Z","iopub.status.busy":"2023-11-03T01:33:16.662875Z","iopub.status.idle":"2023-11-03T01:33:22.537559Z","shell.execute_reply":"2023-11-03T01:33:22.53663Z","shell.execute_reply.started":"2023-11-03T01:33:16.663091Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","> Running on GPU | Num of GPUs:  1\n"]},{"name":"stderr","output_type":"stream","text":["2023-12-22 16:26:43.939325: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-22 16:26:43.941588: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-22 16:26:43.941654: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-22 16:26:43.943602: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-22 16:26:43.943709: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-22 16:26:43.943787: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-22 16:26:44.627975: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-22 16:26:44.628057: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-22 16:26:44.628092: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-12-22 16:26:44.628109: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-22 16:26:44.628150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9272 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"]}],"source":["# Initialize GPU/TPU/TPU-VM\n","strategy, CFG.device = get_device()\n","CFG.replicas = strategy.num_replicas_in_sync"]},{"cell_type":"markdown","metadata":{},"source":["# 📁 | Dataset Path "]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T01:33:22.539581Z","iopub.status.busy":"2023-11-03T01:33:22.539213Z","iopub.status.idle":"2023-11-03T01:33:22.543925Z","shell.execute_reply":"2023-11-03T01:33:22.542981Z","shell.execute_reply.started":"2023-11-03T01:33:22.539546Z"},"trusted":true},"outputs":[],"source":["BASE_PATH = '/kaggle/input'"]},{"cell_type":"markdown","metadata":{},"source":["# 📖 | Meta Data \n","* `{test|train}_essays.csv`\n","    * `id` - A unique identifier for each essay.\n","    * `prompt_id` - Identifies the prompt the essay was written in response to.\n","    * `text` - The essay text itself.\n","    * `generated` - Whether the essay was written by a student (0) or generated by an LLM (1). This field is the target and is not present in test_essays.csv.\n","* **sample_submission.csv** - is the valid sample submission."]},{"cell_type":"markdown","metadata":{},"source":["## Test Data"]},{"cell_type":"code","execution_count":8,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-11-03T01:33:22.545907Z","iopub.status.busy":"2023-11-03T01:33:22.545338Z","iopub.status.idle":"2023-11-03T01:33:22.583165Z","shell.execute_reply":"2023-11-03T01:33:22.582313Z","shell.execute_reply.started":"2023-11-03T01:33:22.545872Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["# Test Data: 3\n","# Sample:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000aaaa</td>\n","      <td>2</td>\n","      <td>Aaa bbb ccc.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1111bbbb</td>\n","      <td>3</td>\n","      <td>Bbb ccc ddd.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id  prompt_id          text\n","0  0000aaaa          2  Aaa bbb ccc.\n","1  1111bbbb          3  Bbb ccc ddd."]},"metadata":{},"output_type":"display_data"}],"source":["test_df = pd.read_csv(f'{BASE_PATH}/test_essays.csv')  # Read CSV file into a DataFrame\n","\n","# Display information about the train data\n","print(\"# Test Data: {:,}\".format(len(test_df)))\n","print(\"# Sample:\")\n","display(test_df.head(2))"]},{"cell_type":"markdown","metadata":{},"source":["# 🍽️ | Preprocessing\n","\n","**What it does:** The preprocessor takes input strings and transforms them into a dictionary (`token_ids`, `padding_mask`) containing preprocessed tensors. This process starts with tokenization, where input strings are converted into sequences of token IDs.\n","\n","**Why it's important:** Initially, raw text data is complex and challenging for modeling due to its high dimensionality. By converting text into a compact set of tokens, such as transforming `\"The quick brown fox\"` into `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]`, we simplify the data. Many models rely on special tokens and additional tensors to understand input. These tokens help divide input and identify padding, among other tasks. Making all sequences the same length through padding boosts computational efficiency, making subsequent steps smoother.\n","\n","Explore the following pages to access the available preprocessing and tokenizer layers in **KerasNLP**:\n","- [Preprocessing](https://keras.io/api/keras_nlp/preprocessing_layers/)\n","- [Tokenizers](https://keras.io/api/keras_nlp/tokenizers/)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T01:33:22.587556Z","iopub.status.busy":"2023-11-03T01:33:22.587042Z","iopub.status.idle":"2023-11-03T01:33:23.363121Z","shell.execute_reply":"2023-11-03T01:33:23.362278Z","shell.execute_reply.started":"2023-11-03T01:33:22.587529Z"},"trusted":true},"outputs":[],"source":["vocab_path = f'{BASE_PATH}/vocab.spm'\n","tokenizer= keras_nlp.models.DebertaV3Tokenizer(vocab_path)\n","preprocessor= keras_nlp.models.DebertaV3Preprocessor(tokenizer, sequence_length=CFG.sequence_length)"]},{"cell_type":"markdown","metadata":{},"source":["Now, let's examine what the output shape of the preprocessing layer looks like. The output shape of the layer can be represented as $(num\\_choices, sequence\\_length)$."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T01:33:23.364807Z","iopub.status.busy":"2023-11-03T01:33:23.364483Z","iopub.status.idle":"2023-11-03T01:33:23.649081Z","shell.execute_reply":"2023-11-03T01:33:23.648089Z","shell.execute_reply.started":"2023-11-03T01:33:23.364781Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["token_ids : torch.Size([200])\n","padding_mask : torch.Size([200])\n"]}],"source":["outs = preprocessor(test_df.text.iloc[0])  # Process options for the first row\n","\n","# Display the shape of each processed output\n","for k, v in outs.items():\n","    print(k, \":\", v.shape)"]},{"cell_type":"markdown","metadata":{},"source":["We'll use the `preprocessing_fn` function to transform each text option using the `dataset.map(preprocessing_fn)` method."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T01:33:23.650811Z","iopub.status.busy":"2023-11-03T01:33:23.650451Z","iopub.status.idle":"2023-11-03T01:33:23.656057Z","shell.execute_reply":"2023-11-03T01:33:23.655184Z","shell.execute_reply.started":"2023-11-03T01:33:23.650778Z"},"trusted":true},"outputs":[],"source":["def preprocess_fn(text, label=None):\n","    text = preprocessor(text)  # Preprocess text\n","    return (text, label) if label is not None else text  # Return processed text and label if available"]},{"cell_type":"markdown","metadata":{},"source":["# 🍚 | DataLoader\n","\n","The code below sets up a robust data flow pipeline using `tf.data.Dataset` for data processing. Notable aspects of `tf.data` include its ability to simplify pipeline construction and represent components in sequences.\n","\n","To learn more about `tf.data`, refer to this [documentation](https://www.tensorflow.org/guide/data)."]},{"cell_type":"code","execution_count":12,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-11-03T01:33:23.657436Z","iopub.status.busy":"2023-11-03T01:33:23.65714Z","iopub.status.idle":"2023-11-03T01:33:23.672707Z","shell.execute_reply":"2023-11-03T01:33:23.671759Z","shell.execute_reply.started":"2023-11-03T01:33:23.657413Z"},"trusted":true},"outputs":[],"source":["def build_dataset(texts, labels=None, batch_size=32,\n","                  cache=False, drop_remainder=True,\n","                  augment=False, repeat=False, shuffle=1024):\n","    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n","    slices = (texts,) if labels is None else (texts, labels)  # Create slices\n","    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n","    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n","    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # Map preprocessing function\n","    ds = ds.repeat() if repeat else ds  # Repeat dataset if enabled\n","    opt = tf.data.Options()  # Create dataset options\n","    if shuffle: \n","        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n","        opt.experimental_deterministic = False\n","    ds = ds.with_options(opt)  # Set dataset options\n","    ds = ds.batch(batch_size, drop_remainder=drop_remainder)  # Batch dataset\n","    ds = ds.prefetch(AUTO)  # Prefetch next batch\n","    return ds  # Return the built dataset"]},{"cell_type":"markdown","metadata":{},"source":["## Fetch Train/test Dataset\n","\n","The function below generates the training and testation datasets for a given fold."]},{"cell_type":"code","execution_count":13,"metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2023-11-03T01:33:23.67408Z","iopub.status.busy":"2023-11-03T01:33:23.673838Z","iopub.status.idle":"2023-11-03T01:33:23.684534Z","shell.execute_reply":"2023-11-03T01:33:23.683695Z","shell.execute_reply.started":"2023-11-03T01:33:23.674059Z"},"trusted":true},"outputs":[],"source":["def get_test_dataset(test_df):\n","    test_texts = test_df.text.tolist()  # Extract testation texts\n","    \n","    # Build testation dataset\n","    test_ds = build_dataset(test_texts, labels=None,\n","                             batch_size=min(CFG.batch_size*CFG.replicas, len(test_df)), cache=False,\n","                             shuffle=False, drop_remainder=False, repeat=False)\n","    \n","    return test_ds  # Return datasets and dataframes"]},{"cell_type":"markdown","metadata":{},"source":["# 🤖 | Modeling\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-11-03T01:33:23.685728Z","iopub.status.busy":"2023-11-03T01:33:23.685442Z","iopub.status.idle":"2023-11-03T01:33:23.695745Z","shell.execute_reply":"2023-11-03T01:33:23.69503Z","shell.execute_reply.started":"2023-11-03T01:33:23.685706Z"},"trusted":true},"outputs":[],"source":["def build_model():\n","    # Create a DebertaV3Classifier model\n","    classifier = keras_nlp.models.DebertaV3Classifier.from_preset(\n","        CFG.preset,\n","        load_weights=False,\n","        preprocessor=None,\n","        num_classes=1 # one output per one option, for five options total 5 outputs\n","    )\n","    inputs = classifier.input\n","    logits = classifier(inputs)\n","        \n","    # Compute final output\n","    outputs = keras.layers.Activation(\"sigmoid\")(logits)\n","    model = keras.Model(inputs, outputs)\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["## Ckpt processing\n","For some reason, `keras.models.load_model` requires write access as `/kaggle/input` doesn't have that access it throws error. Workaround is to simply copy the `ckpts` to other directory then load the model."]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T01:33:23.697072Z","iopub.status.busy":"2023-11-03T01:33:23.696759Z","iopub.status.idle":"2023-11-03T01:33:51.729768Z","shell.execute_reply":"2023-11-03T01:33:51.728673Z","shell.execute_reply.started":"2023-11-03T01:33:23.697041Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total CKPT: 3\n"]}],"source":["# Get the checkpoint directory and name\n","ckpt_dir = CFG.ckpt_dir\n","# ckpt_name = ckpt_dir.split('/')[3]\n","\n","# Copy the checkpoints to a new directory in the /kaggle directory\n","# !cp -r {ckpt_dir} /kaggle/{ckpt_name}\n","\n","# List all the checkpoint paths in the new directory\n","# new_ckpt_dir = f\"/kaggle/{ckpt_name}\"\n","new_ckpt_dir = ckpt_dir\n","ckpt_paths = glob(os.path.join(new_ckpt_dir, 'fold*.keras'))\n","\n","print(\"Total CKPT:\", len(ckpt_paths))"]},{"cell_type":"markdown","metadata":{},"source":["# 🧪 | Prediction"]},{"cell_type":"markdown","metadata":{},"source":["## Inference"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T01:33:51.73167Z","iopub.status.busy":"2023-11-03T01:33:51.73135Z","iopub.status.idle":"2023-11-03T01:39:08.176925Z","shell.execute_reply":"2023-11-03T01:39:08.175993Z","shell.execute_reply.started":"2023-11-03T01:33:51.731639Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23737607dfe64dcfad0abf5bba35a9b1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/bguo/miniconda3/envs/dec23/lib/python3.10/site-packages/keras_core/src/trainers/trainer.py:166: UserWarning: `jit_compile` is not yet enabled for the PyTorch backend. Proceeding with `jit_compile=False`.\n","  warnings.warn(\n","/home/bguo/miniconda3/envs/dec23/lib/python3.10/site-packages/keras_core/src/saving/serialization_lib.py:713: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n","  instance.compile_from_config(compile_config)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n"]}],"source":["# Initialize an array to store predictions for each fold\n","fold_preds = np.zeros(shape=(len(test_df),), dtype='float32')\n","\n","# # Build model\n","# model = build_model()\n","\n","# Iterate through each checkpoint path\n","for ckpt_path in tqdm(ckpt_paths):\n","    # Load the pre-trained model from the checkpoint\n","    model = keras.models.load_model(\n","        ckpt_path,\n","        compile=False,\n","    )\n","#     model.load_weights(ckpt_path)\n","    \n","    # Get the test dataset\n","    test_ds = get_test_dataset(test_df)\n","    \n","    # Generate predictions using the model\n","    preds = model.predict(\n","        test_ds,\n","        batch_size=min(CFG.batch_size * CFG.replicas * 2, len(test_df)),  # Set batch size\n","        verbose=1\n","    )\n","    \n","    # Add predictions to fold_preds and average over checkpoints\n","    fold_preds += preds.squeeze() / len(ckpt_paths)\n","    \n","    # Clean up by deleting the model and collecting garbage\n","    del model\n","    gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["## Check Prediction"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T01:39:08.178727Z","iopub.status.busy":"2023-11-03T01:39:08.178433Z","iopub.status.idle":"2023-11-03T01:39:08.186585Z","shell.execute_reply":"2023-11-03T01:39:08.185663Z","shell.execute_reply.started":"2023-11-03T01:39:08.178701Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["# Predictions\n","\n","❓ Text 1:\n","Aaa bbb ccc.\n","\n","🤖 Predicted: fake\n","\n","------------------------------------------------------------------------------------------ \n","\n","❓ Text 2:\n","Bbb ccc ddd.\n","\n","🤖 Predicted: fake\n","\n","------------------------------------------------------------------------------------------ \n","\n","❓ Text 3:\n","CCC ddd eee.\n","\n","🤖 Predicted: fake\n","\n","------------------------------------------------------------------------------------------ \n","\n"]}],"source":["# Format predictions and true answers\n","pred_answers = (fold_preds > 0.5).astype(int).squeeze()\n","\n","# Check 5 Predictions\n","print(\"# Predictions\\n\")\n","for i in range(3):\n","    row = test_df.iloc[i]\n","    text  = row.text\n","    pred_answer = CFG.label2name[pred_answers[i]]\n","    print(f\"❓ Text {i+1}:\\n{text}\\n\")\n","    print(f\"🤖 Predicted: {pred_answer}\\n\")\n","    print(\"-\"*90, \"\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["# 📮 | Submission"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["array([0.76616454, 0.78856313, 0.7720511 ], dtype=float32)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["fold_preds"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T01:39:08.188208Z","iopub.status.busy":"2023-11-03T01:39:08.18786Z","iopub.status.idle":"2023-11-03T01:39:08.220218Z","shell.execute_reply":"2023-11-03T01:39:08.219291Z","shell.execute_reply.started":"2023-11-03T01:39:08.188172Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>generated</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000aaaa</td>\n","      <td>0.766165</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1111bbbb</td>\n","      <td>0.788563</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id  generated\n","0  0000aaaa   0.766165\n","1  1111bbbb   0.788563"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Create a DataFrame to store the submission\n","sub_df = test_df[[\"id\"]].copy()\n","\n","# Add the formatted predictions to the submission DataFrame\n","sub_df[\"generated\"] = fold_preds.squeeze()\n","\n","# Save Submission\n","sub_df.to_csv('submission.csv',index=False)\n","\n","# Display the first 2 rows of the submission DataFrame\n","sub_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":6888007,"sourceId":61542,"sourceType":"competition"},{"datasetId":3623988,"sourceId":6300093,"sourceType":"datasetVersion"},{"datasetId":3623154,"sourceId":6857742,"sourceType":"datasetVersion"},{"datasetId":3947266,"sourceId":6987454,"sourceType":"datasetVersion"},{"sourceId":151069021,"sourceType":"kernelVersion"}],"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
